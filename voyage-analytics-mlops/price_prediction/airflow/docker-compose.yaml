services:

  # ----------------------------
  # Postgres Database for Airflow
  # ----------------------------
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  # ----------------------------
  # Airflow Initialization
  # ----------------------------
  airflow-init:
    image: apache/airflow:2.9.1-python3.11
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_super_secret_shared_key_123
      - AIRFLOW__CORE__FERNET_KEY=my_super_fernet_key_456
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
      - _PIP_ADDITIONAL_REQUIREMENTS=joblib pandas scikit-learn psycopg2-binary mlflow
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./artifacts:/opt/airflow/artifacts
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"

  # ----------------------------
  # Airflow Webserver
  # ----------------------------
  webserver:
    image: apache/airflow:2.9.1-python3.11
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_super_secret_shared_key_123
      - AIRFLOW__CORE__FERNET_KEY=my_super_fernet_key_456
      - _PIP_ADDITIONAL_REQUIREMENTS=joblib pandas scikit-learn psycopg2-binary mlflow
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./artifacts:/opt/airflow/artifacts
    command: webserver
    restart: always

  # ----------------------------
  # Airflow Scheduler
  # ----------------------------
  scheduler:
    image: apache/airflow:2.9.1-python3.11
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_super_secret_shared_key_123
      - AIRFLOW__CORE__FERNET_KEY=my_super_fernet_key_456
      - _PIP_ADDITIONAL_REQUIREMENTS=joblib pandas scikit-learn psycopg2-binary mlflow
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./artifacts:/opt/airflow/artifacts
    command: scheduler
    restart: always

  # ----------------------------
  # MLFlow Server
  # ----------------------------
  mlflow:
    image: python:3.11-slim
    ports:
      - "5001:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
    working_dir: /mlflow
    command: >
      bash -c "
        pip install mlflow &&
        mlflow server --host 0.0.0.0 --port 5000 \
                      --backend-store-uri sqlite:///mlflow.db \
                      --default-artifact-root /mlflow/mlruns
      "

  # ----------------------------
  # Flask API for prediction
  # ----------------------------
  flight-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    volumes:
      - ./flight_price_model.pkl:/app/flight_price_model.pkl
    depends_on:
      - mlflow

volumes:
  postgres-db-volume:
